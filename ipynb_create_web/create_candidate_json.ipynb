{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymatgen\n",
    "import bson\n",
    "import itertools\n",
    "import numpy as np\n",
    "import collections\n",
    "from bson import ObjectId\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.vis.structure_vtk import EL_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = M.ferroelectric_dataset.distortions\n",
    "workflow_data = M.ferroelectric_dataset.workflow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_for_unitcell(structure):\n",
    "    matrix = structure.lattice.matrix\n",
    "    lines = []\n",
    "    for i in itertools.product([0, 1], repeat=3):\n",
    "        for j in itertools.product([0, 1], repeat=3):\n",
    "            if ((np.max(np.array(j) - np.array(i)) == 1) and \n",
    "                (np.min(np.array(j) - np.array(i)) == 0) and\n",
    "                (np.sum(np.array(j) - np.array(i)) == 1)):\n",
    "                x1, y1, z1 = np.einsum('mn,m->n', matrix, i)\n",
    "                x2, y2, z2 = np.einsum('mn,m->n', matrix, j)\n",
    "                x, y, z = [x1, x2], [y1, y2], [z1, z2]\n",
    "                lines.append([x, y, z])\n",
    "    \n",
    "    coords = structure.cart_coords\n",
    "    species = structure.species\n",
    "    atomic_numbers = [specie.number for specie in species]\n",
    "    species = list(map(str, species))\n",
    "    colors = [\"rgb({},{},{})\".format(*EL_COLORS[\"VESTA\"][s]) for s in species]\n",
    "    xs, ys, zs = coords[:, 0].tolist(), coords[:, 1].tolist(), coords[:, 2].tolist()\n",
    "    data = zip(xs, ys, zs, species, colors)\n",
    "    atoms = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "    for d in data:\n",
    "        x, y, z, s, c = d\n",
    "        atoms[s]['x'].append(x)\n",
    "        atoms[s]['y'].append(y)\n",
    "        atoms[s]['z'].append(z)\n",
    "        \n",
    "#     atoms = {'x': xs, 'y': ys, 'z': zs, 'species': species, 'atomic_numbers': atomic_numbers}\n",
    "        \n",
    "    \n",
    "    legend = list(set(zip(species, colors)))\n",
    "    legend = {s: c for s,c in legend}\n",
    "    return {'unitcell': lines, 'atoms': atoms, 'legend': legend }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarization_plot_data(polarization,\n",
    "                               with_quanta=True,\n",
    "                               abs_ylim_min=5.,\n",
    "                               convert_to_muC_per_cm2=True,\n",
    "                               all_in_polar=True):\n",
    "\n",
    "    polarization_plot_data = {axis: {} for axis in \"abc\"}\n",
    "\n",
    "    same_branch = np.asarray(polarization.get_same_branch_polarization_data(\n",
    "        convert_to_muC_per_cm2=convert_to_muC_per_cm2, all_in_polar=all_in_polar))\n",
    "    quanta = np.asarray(polarization.get_lattice_quanta(\n",
    "        convert_to_muC_per_cm2=convert_to_muC_per_cm2, all_in_polar=all_in_polar))\n",
    "    splines = polarization.same_branch_splines()\n",
    "\n",
    "    for i, axis in enumerate(\"abc\"):\n",
    "        # Make symmetric axis range around zero.\n",
    "        ax_max = max(max(same_branch[:, i]), abs_ylim_min)\n",
    "        ax_min = min(min(same_branch[:, i]), -abs_ylim_min)\n",
    "        ax_range = max(abs(ax_min), ax_max)\n",
    "        polarization_plot_data[axis].update({\"plot_ylim\": (-ax_range, ax_range)})\n",
    "        polarization_plot_data[axis].update({\"plot_xlim\": (0, len(same_branch[:, i]) - 1)})\n",
    "\n",
    "        # Plot same branch polarization with quanta\n",
    "        polarization_plot_data[axis].update({'quanta': {'data': [], 'color': []}})\n",
    "        num_copies_quanta = 2 * int(np.ceil((ax_max - ax_min) / quanta[0, i]))\n",
    "        for j in range(-num_copies_quanta, num_copies_quanta + 1):\n",
    "            color = 'ro' if j == 0 else 'bo'\n",
    "            polarization_plot_data[axis]['quanta']['data'].append(\n",
    "                (same_branch[:, i].flatten() + j * np.array(quanta[:, i].flatten())).tolist())\n",
    "            polarization_plot_data[axis]['quanta']['color'].append(color)\n",
    "\n",
    "        # Plot same branch polarization spline\n",
    "        polarization_plot_data[axis].update({'splines': {}})\n",
    "        if splines[i]:\n",
    "            xs = np.linspace(0, len(same_branch[:, i]) - 1, 1000)\n",
    "            polarization_plot_data[axis]['splines'].update(\n",
    "                {'x': xs.tolist(), 'y': splines[i](xs).tolist()})\n",
    "\n",
    "    return polarization_plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarization_from_workflow_data(wfid_str):\n",
    "    import pymatgen.analysis.ferroelectricity.polarization as polarization\n",
    "    entry = workflow_data.find_one({'wfid': wfid_str})\n",
    "    vasp_structs = list(map(pymatgen.Structure.from_dict, entry['structures']))\n",
    "    vasp_pelecs = entry['raw_electron_polarization']\n",
    "    vasp_pions = entry['raw_ionic_polarization']\n",
    "    return polarization.Polarization(vasp_pelecs, vasp_pions, vasp_structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalar_plot_dict(scalars):\n",
    "    import pymatgen.analysis.ferroelectricity.polarization as polarization\n",
    "    energy_trend = polarization.EnergyTrend(scalars)\n",
    "    spline = energy_trend.spline()\n",
    "    spline_xs = np.linspace(0, len(scalars)-1, num=50)\n",
    "    spline_ys = spline(spline_xs)\n",
    "    return {'scalars': scalars, 'spline': {'x': spline_xs.tolist(), 'y': spline_ys.tolist()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_tables(wfid_str):\n",
    "    all_labels = collections.OrderedDict()\n",
    "    \n",
    "    # Create default table of False values\n",
    "    relaxation_task_labels = collections.OrderedDict()\n",
    "    relaxation_task_labels.update({'nonpolar_relaxation': False})\n",
    "    relaxation_task_labels.update({'polar_relaxation': False})\n",
    "    \n",
    "    static_task_labels = collections.OrderedDict()\n",
    "    static_task_labels.update({'nonpolar_static': False})\n",
    "    for i in range(8,0,-1):\n",
    "        static_task_labels.update({'interpolation_{}_static'.format(i): False})\n",
    "    static_task_labels.update({'polar_static': False})\n",
    "    \n",
    "    polarization_task_labels = collections.OrderedDict()\n",
    "    polarization_task_labels.update({'nonpolar_polarization': False})\n",
    "    for i in range(8,0,-1):\n",
    "        polarization_task_labels.update({'interpolation_{}_polarization'.format(i): False})\n",
    "    polarization_task_labels.update({'polar_polarization': False})\n",
    "    \n",
    "    all_labels.update({'relaxation_task_labels': relaxation_task_labels})\n",
    "    all_labels.update({'static_task_labels': static_task_labels})\n",
    "    all_labels.update({'polarization_task_labels': polarization_task_labels})\n",
    "    \n",
    "    # Update default table with Trues\n",
    "    entry = workflow_data.find_one({'wfid': wfid_str})\n",
    "    relax_labels = [] if 'relaxation_task_labels' not in entry else entry['relaxation_task_labels']\n",
    "    static_labels = [] if 'static_task_labels' not in entry else entry['static_task_labels']\n",
    "    pol_labels = [] if 'polarization_task_labels' not in entry else entry['polarization_task_labels']\n",
    "    \n",
    "    for label in relax_labels:\n",
    "        all_labels['relaxation_task_labels'][label] = True\n",
    "    for label in static_labels:\n",
    "        all_labels['static_task_labels'][label] = True\n",
    "    for i, label in enumerate(pol_labels):\n",
    "        if entry['raw_electron_polarization'][i] is not None:\n",
    "            all_labels['polarization_task_labels'][label] = True\n",
    "            \n",
    "    json_table_data = {key: [] for key in all_labels}\n",
    "    for key in all_labels:\n",
    "        for subkey in all_labels[key]:\n",
    "            json_table_data[key].append({\"task\": subkey, \"complete\": all_labels[key][subkey]})\n",
    "    return json_table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following categories for the dataset:  \n",
    "  smooth -- workflows with a high quality reconstructed polarization and energy trend  \n",
    "  not smooth -- workflows that have all polarization calculations completed but reconstructed trends are not smooth  \n",
    "  static_only -- workflows that are missing polarization data but otherwise completed  \n",
    "  not_complete -- all other incomplete workflows (Includes DEFUSED, FIZZLED, and RUNNING workflow states)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VALUES\n",
    "# smooth:  183\n",
    "# not_smooth:  56\n",
    "# static_only:  42\n",
    "# not_complete:  133\n",
    "\n",
    "# NEW VALUES (2018.12.10)\n",
    "# smooth:  184\n",
    "# not_smooth:  55\n",
    "# static_only:  42\n",
    "# not_complete:  133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smooth:  184\n",
      "not_smooth:  55\n",
      "static_only:  42\n",
      "not_complete:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tess/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "/home/tess/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "/home/tess/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "/home/tess/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n"
     ]
    }
   ],
   "source": [
    "smooth = workflow_data.find({'polarization_len' : 10,\n",
    "                             'polarization_max_spline_jumps': {\"$exists\": True, \"$not\" : { \"$gt\" : 1 }},\n",
    "                             'energies_per_atom_max_spline_jumps': {'$lte': 1e-2}})\n",
    "not_smooth = workflow_data.find({'polarization_len' : 10,\n",
    "                                 'polarization_change_norm': {'$exists': True},\n",
    "                                 '$or': [{'polarization_max_spline_jumps': { \"$gt\" : 1 }},\n",
    "                                         {'energies_per_atom_max_spline_jumps': {'$gt': 1e-2}}]})\n",
    "static = workflow_data.find({'$or': [{'polarization_len' : {'$lt': 10}},\n",
    "                                     {'polarization_change_norm': {'$exists': False}}],\n",
    "                             'static_len': 10,\n",
    "                             'workflow_status': 'COMPLETED'})\n",
    "defused_or_fizzled_or_running = workflow_data.find(\n",
    "    {'$and': [{'$or': [{'polarization_len' : {'$lt': 10}},\n",
    "                       {'polarization_change_norm': {'$exists': False}}]},\n",
    "              {'$or': [{'workflow_status': 'DEFUSED'}, \n",
    "                       {'workflow_status': 'FIZZLED'}, \n",
    "                       {'workflow_status': 'RUNNING'}]}]})\n",
    "print(\"smooth: \", smooth.count())\n",
    "print(\"not_smooth: \", not_smooth.count())\n",
    "print(\"static_only: \", static.count())\n",
    "print(\"not_complete: \", defused_or_fizzled_or_running.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alphabetical_formula(pretty_formula):\n",
    "    from pymatgen.core.composition import Composition\n",
    "    alphabetical_formula = Composition(pretty_formula).alphabetical_formula.split()\n",
    "    # Remove 1s\n",
    "    alphabetical_formula = [string[:-1] if (string[-1] == \"1\" and string[-2] not in \"0123456789\") else string for string in alphabetical_formula]\n",
    "    # Stringify\n",
    "    alphabetical_formula = \"\".join(alphabetical_formula)\n",
    "    return alphabetical_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_candidate_json(pymongo_result, category):\n",
    "    for workflow_entry in pymongo_result:\n",
    "        distort = None\n",
    "        entry_dict = {workflow_entry['wfid']: {}}\n",
    "        \n",
    "        #Polarization data\n",
    "        if 'polarization_change_norm' in workflow_entry:\n",
    "            # Need to reach into distortion database to get structures \n",
    "            # for incomplete 'structures' array in workflow data.\n",
    "            entry_polarization = get_polarization_from_workflow_data(workflow_entry['wfid'])\n",
    "            entry_pol_plot_data = get_polarization_plot_data(entry_polarization)\n",
    "            entry_dict[workflow_entry['wfid']].update({'polarization': entry_pol_plot_data})\n",
    "            entry_dict[workflow_entry['wfid']].update({'polarization_change_norm': workflow_entry['polarization_change_norm']})\n",
    "\n",
    "        # Distortion data\n",
    "        if 'structures' not in workflow_entry or len(workflow_entry['structures']) < 10:\n",
    "            cid = workflow_entry['cid']\n",
    "            distort = distortions.find_one({'_id': ObjectId(cid[4:])})\n",
    "            nonpolar = Structure.from_dict(distort['distortion']['high_low_setting'])\n",
    "            polar = Structure.from_dict(distort['distortion']['low_symm'])\n",
    "            all_structs = nonpolar.interpolate(polar, nimages=9, interpolate_lattices=True)\n",
    "        else: \n",
    "            all_structs = list(map(pymatgen.core.structure.Structure.from_dict, workflow_entry['structures']))   \n",
    "        entry_dict[workflow_entry['wfid']].update({'distortion' : list(map(create_metadata_for_unitcell, all_structs))})\n",
    "\n",
    "        # Energy data\n",
    "        if ('energies_per_atom' in workflow_entry and \n",
    "            'static_len' in workflow_entry and \n",
    "             workflow_entry['static_len'] == 10):\n",
    "            entry_dict[workflow_entry['wfid']].update(\n",
    "                {'energy_per_atom': get_scalar_plot_dict(workflow_entry['energies_per_atom'])})\n",
    "\n",
    "        entry_dict[workflow_entry['wfid']].update(\n",
    "            {\n",
    "                'nonpolar_id': workflow_entry['nonpolar_id'],\n",
    "                'polar_id': workflow_entry['polar_id'],\n",
    "                'nonpolar_spacegroup': workflow_entry['nonpolar_spacegroup'],\n",
    "                'polar_spacegroup': workflow_entry['polar_spacegroup'],\n",
    "                'pretty_formula': distort['pretty_formula'] if distort is not None else workflow_entry['pretty_formula'],\n",
    "                'alphabetical_formula': get_alphabetical_formula(distort['pretty_formula']) if distort is not None else workflow_entry['alphabetical_formula'],\n",
    "                'hubbards': None if 'hubbards' not in workflow_entry else workflow_entry['hubbards'],\n",
    "                'workflow_status': workflow_entry['workflow_status'],\n",
    "            })\n",
    "        entry_dict[workflow_entry['wfid']].update({'tasks' : get_task_tables(workflow_entry['wfid'])})\n",
    "        entry_dict[workflow_entry['wfid']].update({'category' : category})\n",
    "\n",
    "        import json\n",
    "        with open(\"../json/\"+ workflow_entry['wfid']+'.json', 'w') as fp:\n",
    "            json.dump(entry_dict, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"smooth\", \"not_smooth\", \"static_only\", \"not_complete\"]\n",
    "pymongo_results = [smooth, not_smooth, static, defused_or_fizzled_or_running]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  smooth\n",
      "category:  not_smooth\n",
      "category:  static_only\n",
      "category:  not_complete\n"
     ]
    }
   ],
   "source": [
    "for pymongo_result, category in zip(pymongo_results, categories):\n",
    "    print(\"category: \", category)\n",
    "    make_candidate_json(pymongo_result, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.6.6"
=======
   "version": "3.6.8"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
